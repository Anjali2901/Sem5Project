{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Anjali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Anjali\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import  WordNetLemmatizer\n",
    "lemmatizer =  WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string \n",
    "#stops = set(stopwords.words('english'))\n",
    "stops = list(string.punctuation)\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 31.192660550458715 %\n",
      "Negative tweets percentage: 21.3302752293578 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @CasonBrittney: Lol you bitches don't even know how to be real friends... Just a bunch of messy, fake ass, 2 faced, scandalous, no loyalâ€¦\n",
      "Important results @intmedpress that confirmed what numbers of my colleagues have been doing in clinical practice foâ€¦ https://t.co/IYRzYeeE0l\n",
      "RT @ACLUTx: It's week 2 of early voting in Texas!\n",
      "\n",
      "If you experience problems voting or voter intimidation, call the Election Protection Hoâ€¦\n",
      "@barberk007 @dawnward4 To much booze and 2 faced\n",
      "It's week 2 of early voting in Texas!\n",
      "\n",
      "If you experience problems voting or voter intimidation, call the Election Pâ€¦ https://t.co/56ReC5Hxus\n",
      "RT @faduda: Irish news media, faced with a country where 2/3 of voters approved gay marriage and abortion liberalisation, hunt for new edgeâ€¦\n",
      "@RiaRevealed @KishwerM @princenarula88 @ms_dipika It's very easy to compare ppl.. Bt can u compare circumstances diâ€¦ https://t.co/mrKB5wo2HW\n",
      "RT @TeanerWiener: 10/28/2018 \n",
      "#Tua - 70.4 comp % ; 2066 passing yards and 25 TDâ€™s... 123 yds rushing  - 4.7 per carry - faced 0 top 20 Defâ€¦\n",
      "RT @BethRomelus: The \"slavery was a choice\" debate shows how many of y'all have overestimated your talents, intelligence, willpower, and meâ€¦\n",
      "RT @MalikHeath2: Ready to leave cause itâ€™s alot of 2 faced people fr fr ðŸ’¯\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "RT @jssoldiers: Dear All, Please use the hash tag #RegisterVoteForAccountability\n",
      "And participate \n",
      "We hardly have 2 Days and people still faâ€¦\n",
      "RT @SrinuIndian1: Dear All, Please use the hash tag #RegisterVoteForAccountability\n",
      "And participate \n",
      "We hardly have 2 Days and people stillâ€¦\n",
      "Dear All, Please use the hash tag #RegisterVoteForAccountability\n",
      "And participate \n",
      "We hardly have 2 Days and peopleâ€¦ https://t.co/hWLEjVqacF\n",
      "I can't tolerate:\n",
      "1. Double faced&amp;egoistic people like PLANKY .\n",
      "2. Double faced&amp;egoistic people like PLANKY .\n",
      "3. \"\"â€¦ https://t.co/dtUkxHjoSD\n",
      "@NitinNitin1978 I'm sorry for the trouble you've faced regarding the return of your product. Please drop your detaiâ€¦ https://t.co/OYEVf1JL17\n",
      "Dear All, Please use the hash tag #RegisterVoteForAccountability\n",
      "And participate \n",
      "We hardly have 2 Days and peopleâ€¦ https://t.co/ApeqNHiBBq\n",
      "@NoddyAkhtar I'm sorry for the inconvenience you faced with regards to the delivery of your order. We would like toâ€¦ https://t.co/pJh48FtFKz\n",
      "@BobbyMilone29 We were 8 wins behind the Red Sox in the regular season, and weâ€™ll call it 2 wins behind them in theâ€¦ https://t.co/eQT8A6ep4v\n",
      "@kilmeade @RepPeteKing Peter King is a 2 faced lier \n",
      "Another corrupt NY POLITICIAN N YOU SHOULD KNOW THIS..\n",
      "@NirupamaNiru7 I'm sorry you've faced issue with the incorrect tracking update of your order. Get in touch with ourâ€¦ https://t.co/WrwsmMr3MJ\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import csv\n",
    "\n",
    "class TwitterClient(object): \n",
    "\n",
    "    def __init__(self): \n",
    "        consumer_key = \"rXBTXz6yE6VjactwIFfQEHLwX\"\n",
    "        consumer_secret = \"3wluIGBoyitUyr8m0HRhiap6UhUFkGskWJ2DA0J7v4es9Dfhwo\"\n",
    "        access_token = \"1055057699078107137-ntZ1ReqvsUvpPDJpKjUaV5oc0m8zhb\"\n",
    "        access_token_secret = \"39Ew12bFgpyITIjo9GOhvD2R3mlpwvrbvAaCE5XmGQYm4\"\n",
    "\n",
    "\n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())         \n",
    "        \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 1\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 0\n",
    "        else: \n",
    "            return -1\n",
    "\n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "\n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            file_name = open(\"test.txt\",\"r\") \n",
    "            train = \"train.csv\"\n",
    "            csvf = open(\"train.csv\",\"w\")\n",
    "            csvwriter = csv.writer(csvf)\n",
    "            row = [\"text\",\"sentiment\"]\n",
    "            csvwriter.writerow(row)\n",
    "            for line in file_name:\n",
    "                fetched_tweets = self.api.search(q = line, count = count) \n",
    "  \n",
    "                # parsing tweets one by one \n",
    "                for tweet in fetched_tweets: \n",
    "                    # empty dictionary to store required params of a tweet \n",
    "                    parsed_tweet = {} \n",
    "  \n",
    "                    # saving text of tweet \n",
    "                    parsed_tweet['text'] = tweet.text \n",
    "                    # saving sentiment of tweet \n",
    "                    parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "\n",
    "                    # appending parsed tweet to tweets list \n",
    "                    if tweet.retweet_count > 0: \n",
    "                        # if tweet has retweets, ensure that it is appended only once \n",
    "                        if parsed_tweet not in tweets: \n",
    "                            tweets.append(parsed_tweet)\n",
    "                            \n",
    "                    else: \n",
    "                        tweets.append(parsed_tweet)\n",
    "                    #tweets is our list \n",
    "                    f=0\n",
    "                    val1 = \"\"\n",
    "                    val2 = \"\"\n",
    "                    for i in tweets:\n",
    "                        for key, value in i.items():\n",
    "                            if(f==0):\n",
    "                                val1=value\n",
    "                                f=1\n",
    "                            else :\n",
    "                                f=0\n",
    "                                val2=value\n",
    "                        val1 = val1.replace(',', '')\n",
    "                        row = [val1.encode(\"utf8\"),val2]\n",
    "                        csvwriter.writerow(row)  \n",
    "            #csvf.close()\n",
    "            return tweets \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "\n",
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 1] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == -1] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    #print(\"Neutral tweets percentage: {} %\".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "\n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "\n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'RT @SrinuIndian1: Dear All Please use the ha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b'RT @SrinuIndian1: Dear All Please use the ha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'Dear All Please use the hash tag #RegisterVo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b'RT @SrinuIndian1: Dear All Please use the ha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b'Dear All Please use the hash tag #RegisterVo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'RT @SrinuIndian1: Dear All Please use the ha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b'Dear All Please use the hash tag #RegisterVo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b\"RT @CasonBrittney: Lol you bitches don't eve...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'RT @jssoldiers: Dear All Please use the hash...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b'Important results @intmedpress that confirme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b'RT @SrinuIndian1: Dear All Please use the ha...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b'Dear All Please use the hash tag #RegisterVo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148583</th>\n",
       "      <td>b'I HAVE every right to criticize abominate th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148584</th>\n",
       "      <td>b'I abominate\\nRage\\nBoiling deep to murder\\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148585</th>\n",
       "      <td>b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148586</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148587</th>\n",
       "      <td>b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148588</th>\n",
       "      <td>b\"@benjamindcrosby @nosdnomde All of the ireni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148589</th>\n",
       "      <td>b'RT @EricHofferDaily: Ours is a golden age of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148590</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148591</th>\n",
       "      <td>b'Loathe | Definition by Merriam-Webster\\nhate...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148592</th>\n",
       "      <td>b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148593</th>\n",
       "      <td>b\"I abominate\\nRage\\nBoiling deep inside\\nTo b...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148594</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148595</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148596</th>\n",
       "      <td>b'RT @ricsl1600: Like every man of sense and g...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148597</th>\n",
       "      <td>b'Like every man of sense and good feeling I a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148598</th>\n",
       "      <td>b'RT @DoyleAbominator: Repost from doylewolfga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148599</th>\n",
       "      <td>b'Repost from @doylewolfgangvonfrankenstein us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148600</th>\n",
       "      <td>b'Repost from doylewolfgangvonfrankenstein usi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148601</th>\n",
       "      <td>b'Repost from doylewolfgangvonfrankenstein usi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148602</th>\n",
       "      <td>b'\\xe7\\xa7\\x81\\xe3\\x80\\x81\\xe5\\xad\\xa6\\xe5\\x8b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148603</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148604</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148605</th>\n",
       "      <td>b'@TheLondonDebate @KeloidKrown @JohnCarson64 ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148606</th>\n",
       "      <td>b'\\xe2\\x80\\x9cI have been in a serious battle ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148607</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148608</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148609</th>\n",
       "      <td>b'Our #village can have no peace until Cora th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148610</th>\n",
       "      <td>b'@DestiGrace1 @craigunger @GOP detest abhor l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148611</th>\n",
       "      <td>b\"abominate /\\xc9\\x99b\\xc9\\x91'm\\xc9\\x99n\\xc3\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148612</th>\n",
       "      <td>b'an immensity considers a wench: abominate ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148613 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  sentiment\n",
       "0       b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "1       b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "2       b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "3       b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "4       b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "5       b'Important results @intmedpress that confirme...          1\n",
       "6       b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "7       b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "8       b'Important results @intmedpress that confirme...          1\n",
       "9       b'RT @SrinuIndian1: Dear All Please use the ha...         -1\n",
       "10      b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "11      b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "12      b'Important results @intmedpress that confirme...          1\n",
       "13      b'RT @SrinuIndian1: Dear All Please use the ha...         -1\n",
       "14      b'Dear All Please use the hash tag #RegisterVo...         -1\n",
       "15      b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "16      b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "17      b'Important results @intmedpress that confirme...          1\n",
       "18      b'RT @SrinuIndian1: Dear All Please use the ha...         -1\n",
       "19      b'Dear All Please use the hash tag #RegisterVo...         -1\n",
       "20      b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "21      b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "22      b'Important results @intmedpress that confirme...          1\n",
       "23      b'RT @SrinuIndian1: Dear All Please use the ha...         -1\n",
       "24      b'Dear All Please use the hash tag #RegisterVo...         -1\n",
       "25      b\"RT @CasonBrittney: Lol you bitches don't eve...          1\n",
       "26      b'RT @jssoldiers: Dear All Please use the hash...         -1\n",
       "27      b'Important results @intmedpress that confirme...          1\n",
       "28      b'RT @SrinuIndian1: Dear All Please use the ha...         -1\n",
       "29      b'Dear All Please use the hash tag #RegisterVo...         -1\n",
       "...                                                   ...        ...\n",
       "148583  b'I HAVE every right to criticize abominate th...          1\n",
       "148584  b'I abominate\\nRage\\nBoiling deep to murder\\n\\...          1\n",
       "148585  b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...          0\n",
       "148586  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...          0\n",
       "148587  b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...          0\n",
       "148588  b\"@benjamindcrosby @nosdnomde All of the ireni...          0\n",
       "148589  b'RT @EricHofferDaily: Ours is a golden age of...          1\n",
       "148590  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...          0\n",
       "148591  b'Loathe | Definition by Merriam-Webster\\nhate...         -1\n",
       "148592  b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...          0\n",
       "148593  b\"I abominate\\nRage\\nBoiling deep inside\\nTo b...         -1\n",
       "148594  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...          0\n",
       "148595  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...          1\n",
       "148596  b'RT @ricsl1600: Like every man of sense and g...          1\n",
       "148597  b'Like every man of sense and good feeling I a...          1\n",
       "148598  b'RT @DoyleAbominator: Repost from doylewolfga...          0\n",
       "148599  b'Repost from @doylewolfgangvonfrankenstein us...          0\n",
       "148600  b'Repost from doylewolfgangvonfrankenstein usi...          0\n",
       "148601  b'Repost from doylewolfgangvonfrankenstein usi...          0\n",
       "148602  b'\\xe7\\xa7\\x81\\xe3\\x80\\x81\\xe5\\xad\\xa6\\xe5\\x8b...          0\n",
       "148603  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...          0\n",
       "148604  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...          1\n",
       "148605  b'@TheLondonDebate @KeloidKrown @JohnCarson64 ...         -1\n",
       "148606  b'\\xe2\\x80\\x9cI have been in a serious battle ...         -1\n",
       "148607  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...          0\n",
       "148608  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...          1\n",
       "148609  b'Our #village can have no peace until Cora th...          0\n",
       "148610  b'@DestiGrace1 @craigunger @GOP detest abhor l...          0\n",
       "148611  b\"abominate /\\xc9\\x99b\\xc9\\x91'm\\xc9\\x99n\\xc3\\...          0\n",
       "148612  b'an immensity considers a wench: abominate ad...          0\n",
       "\n",
       "[148613 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"train.csv\");\n",
    "df1 = df\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "y = df['sentiment']\n",
    "x = df['text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],df['sentiment'] , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROCESSED_FILE = 'train-processed.csv'\n",
    "TEST_PROCESSED_FILE = 'test-processed.csv'\n",
    "X_test.to_csv(TEST_PROCESSED_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = pd.concat([X_train, y_train,], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_csv(TRAIN_PROCESSED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct = 36.33%\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Classifies a tweet based on the number of positive and negative words in it\n",
    "POSITIVE_WORDS_FILE = 'positive-words.txt'\n",
    "NEGATIVE_WORDS_FILE = 'negative-words.txt'\n",
    "TRAIN = True\n",
    "\n",
    "def funct(l):\n",
    "    if(l==\"negative\"):\n",
    "        return -1\n",
    "    elif(l==\"positive\"):\n",
    "        return 1\n",
    "    else :\n",
    "        return 0\n",
    "def classify(processed_csv, test_file=True, **params):\n",
    "    positive_words = utils.file_to_wordset(params.pop('positive_words'))\n",
    "    negative_words = utils.file_to_wordset(params.pop('negative_words'))\n",
    "    predictions = []\n",
    "    with open(processed_csv, 'r') as csv:\n",
    "        for line in csv:\n",
    "            if test_file:\n",
    "                tweet_id, tweet = line.strip().split(',')\n",
    "            else:\n",
    "                tweet_id,tweet,label= line.strip().split(',')\n",
    "            pos_count, neg_count = 0, 0\n",
    "            for word in tweet.split():\n",
    "                if word in positive_words:\n",
    "                    pos_count += 1\n",
    "                elif word in negative_words:\n",
    "                    neg_count += 1\n",
    "            # print pos_count, neg_count\n",
    "            prediction = 1 if pos_count >= neg_count else 0\n",
    "            if test_file:\n",
    "                predictions.append((tweet_id, prediction))\n",
    "            else:\n",
    "                predictions.append((tweet_id, funct(label), prediction))\n",
    "    return predictions\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if TRAIN:\n",
    "        predictions = classify(TRAIN_PROCESSED_FILE, test_file=(not TRAIN), positive_words=POSITIVE_WORDS_FILE, negative_words=NEGATIVE_WORDS_FILE)\n",
    "        correct = sum([1 for p in predictions if p[1] == p[2]]) * 100.0 / len(predictions)\n",
    "        print('Correct = %.2f%%' % correct)\n",
    "    else:\n",
    "        predictions = classify(TEST_PROCESSED_FILE, test_file=(not TRAIN), positive_words=POSITIVE_WORDS_FILE, negative_words=NEGATIVE_WORDS_FILE)\n",
    "        utils.save_results_to_csv(predictions, 'baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118891\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_PROCESSED_FILE, 'r') as csv:\n",
    "        lines = csv.readlines()\n",
    "        #print(lines)\n",
    "        total = len(lines)\n",
    "        for i in range(total//10000):\n",
    "            print(lines)\n",
    "        print(total)\n",
    "        #for i, line in enumerate(lines):\n",
    "            #print(i)\n",
    "            #print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
