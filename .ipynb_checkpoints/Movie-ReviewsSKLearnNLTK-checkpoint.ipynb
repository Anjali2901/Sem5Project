{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capsule', ':', 'in', '2176', 'on', 'the', 'planet', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words(movie_reviews.fileids()[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...], 'neg'),\n",
       " (['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...], 'neg'),\n",
       " (['it', 'is', 'movies', 'like', 'these', 'that', 'make', ...], 'neg'),\n",
       " (['\"', 'quest', 'for', 'camelot', '\"', 'is', 'warner', ...], 'neg'),\n",
       " (['synopsis', ':', 'a', 'mentally', 'unstable', 'man', ...], 'neg')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "for category in movie_reviews.categories():\n",
    "    for fileid in movie_reviews.fileids(category):\n",
    "        documents.append((movie_reviews.words(fileid), category))\n",
    "documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['it', \"'\", 's', 'always', 'a', 'bad', 'sign', 'when', ...], 'neg'),\n",
       " (['jacques', 'tati', \"'\", 's', '1953', 'classic', '\"', ...], 'pos'),\n",
       " (['_soldier_', 'is', 'hands', 'down', 'one', 'of', ...], 'neg'),\n",
       " (['ralph', 'fiennes', 'is', 'carving', 'out', 'a', ...], 'pos'),\n",
       " (['errol', 'morris', ',', 'critically', 'acclaimed', ...], 'pos')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.shuffle(documents)\n",
    "documents[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    \n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('better', 'RBR')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "w = \"better\"\n",
    "pos_tag([w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'!',\n",
       "  '\"',\n",
       "  '#',\n",
       "  '$',\n",
       "  '%',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  '(',\n",
       "  ')',\n",
       "  '*',\n",
       "  '+',\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '/',\n",
       "  ':',\n",
       "  ';',\n",
       "  '<',\n",
       "  '=',\n",
       "  '>',\n",
       "  '?',\n",
       "  '@',\n",
       "  '[',\n",
       "  '\\\\',\n",
       "  ']',\n",
       "  '^',\n",
       "  '_',\n",
       "  '`',\n",
       "  'a',\n",
       "  'about',\n",
       "  'above',\n",
       "  'after',\n",
       "  'again',\n",
       "  'against',\n",
       "  'ain',\n",
       "  'all',\n",
       "  'am',\n",
       "  'an',\n",
       "  'and',\n",
       "  'any',\n",
       "  'are',\n",
       "  'aren',\n",
       "  \"aren't\",\n",
       "  'as',\n",
       "  'at',\n",
       "  'be',\n",
       "  'because',\n",
       "  'been',\n",
       "  'before',\n",
       "  'being',\n",
       "  'below',\n",
       "  'between',\n",
       "  'both',\n",
       "  'but',\n",
       "  'by',\n",
       "  'can',\n",
       "  'couldn',\n",
       "  \"couldn't\",\n",
       "  'd',\n",
       "  'did',\n",
       "  'didn',\n",
       "  \"didn't\",\n",
       "  'do',\n",
       "  'does',\n",
       "  'doesn',\n",
       "  \"doesn't\",\n",
       "  'doing',\n",
       "  'don',\n",
       "  \"don't\",\n",
       "  'down',\n",
       "  'during',\n",
       "  'each',\n",
       "  'few',\n",
       "  'for',\n",
       "  'from',\n",
       "  'further',\n",
       "  'had',\n",
       "  'hadn',\n",
       "  \"hadn't\",\n",
       "  'has',\n",
       "  'hasn',\n",
       "  \"hasn't\",\n",
       "  'have',\n",
       "  'haven',\n",
       "  \"haven't\",\n",
       "  'having',\n",
       "  'he',\n",
       "  'her',\n",
       "  'here',\n",
       "  'hers',\n",
       "  'herself',\n",
       "  'him',\n",
       "  'himself',\n",
       "  'his',\n",
       "  'how',\n",
       "  'i',\n",
       "  'if',\n",
       "  'in',\n",
       "  'into',\n",
       "  'is',\n",
       "  'isn',\n",
       "  \"isn't\",\n",
       "  'it',\n",
       "  \"it's\",\n",
       "  'its',\n",
       "  'itself',\n",
       "  'just',\n",
       "  'll',\n",
       "  'm',\n",
       "  'ma',\n",
       "  'me',\n",
       "  'mightn',\n",
       "  \"mightn't\",\n",
       "  'more',\n",
       "  'most',\n",
       "  'mustn',\n",
       "  \"mustn't\",\n",
       "  'my',\n",
       "  'myself',\n",
       "  'needn',\n",
       "  \"needn't\",\n",
       "  'no',\n",
       "  'nor',\n",
       "  'not',\n",
       "  'now',\n",
       "  'o',\n",
       "  'of',\n",
       "  'off',\n",
       "  'on',\n",
       "  'once',\n",
       "  'only',\n",
       "  'or',\n",
       "  'other',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'out',\n",
       "  'over',\n",
       "  'own',\n",
       "  're',\n",
       "  's',\n",
       "  'same',\n",
       "  'shan',\n",
       "  \"shan't\",\n",
       "  'she',\n",
       "  \"she's\",\n",
       "  'should',\n",
       "  \"should've\",\n",
       "  'shouldn',\n",
       "  \"shouldn't\",\n",
       "  'so',\n",
       "  'some',\n",
       "  'such',\n",
       "  't',\n",
       "  'than',\n",
       "  'that',\n",
       "  \"that'll\",\n",
       "  'the',\n",
       "  'their',\n",
       "  'theirs',\n",
       "  'them',\n",
       "  'themselves',\n",
       "  'then',\n",
       "  'there',\n",
       "  'these',\n",
       "  'they',\n",
       "  'this',\n",
       "  'those',\n",
       "  'through',\n",
       "  'to',\n",
       "  'too',\n",
       "  'under',\n",
       "  'until',\n",
       "  'up',\n",
       "  've',\n",
       "  'very',\n",
       "  'was',\n",
       "  'wasn',\n",
       "  \"wasn't\",\n",
       "  'we',\n",
       "  'were',\n",
       "  'weren',\n",
       "  \"weren't\",\n",
       "  'what',\n",
       "  'when',\n",
       "  'where',\n",
       "  'which',\n",
       "  'while',\n",
       "  'who',\n",
       "  'whom',\n",
       "  'why',\n",
       "  'will',\n",
       "  'with',\n",
       "  'won',\n",
       "  \"won't\",\n",
       "  'wouldn',\n",
       "  \"wouldn't\",\n",
       "  'y',\n",
       "  'you',\n",
       "  \"you'd\",\n",
       "  \"you'll\",\n",
       "  \"you're\",\n",
       "  \"you've\",\n",
       "  'your',\n",
       "  'yours',\n",
       "  'yourself',\n",
       "  'yourselves',\n",
       "  '{',\n",
       "  '|',\n",
       "  '}',\n",
       "  '~'},\n",
       " '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stops = set(stopwords.words('english'))\n",
    "punctuations = list(string.punctuation)\n",
    "stops.update(punctuations)\n",
    "stops, string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stops:\n",
    "            pos = pos_tag([w])\n",
    "            clean_word = lemmatizer.lemmatize(w, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 2000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jacques',\n",
       " 'tati',\n",
       " '1953',\n",
       " 'classic',\n",
       " 'le',\n",
       " 'vacances',\n",
       " 'de',\n",
       " 'hulot',\n",
       " 'also',\n",
       " 'know',\n",
       " 'mr',\n",
       " 'hulot',\n",
       " 'vacation',\n",
       " 'english',\n",
       " 'ought',\n",
       " 'textbook',\n",
       " 'non',\n",
       " 'dialogue',\n",
       " 'comedy',\n",
       " 'film',\n",
       " 'character',\n",
       " 'hardly',\n",
       " 'ever',\n",
       " 'speak',\n",
       " 'directly',\n",
       " 'film',\n",
       " 'operates',\n",
       " 'paper',\n",
       " 'thin',\n",
       " 'premise',\n",
       " 'monsieur',\n",
       " 'hulot',\n",
       " 'played',\n",
       " 'tati',\n",
       " 'awkward',\n",
       " 'clumsy',\n",
       " 'generally',\n",
       " 'manages',\n",
       " 'annoy',\n",
       " 'guest',\n",
       " 'beach',\n",
       " 'resort',\n",
       " 'hotel',\n",
       " 'take',\n",
       " 'week',\n",
       " 'vacation',\n",
       " 'yet',\n",
       " 'film',\n",
       " 'beside',\n",
       " 'laugh',\n",
       " 'consistently',\n",
       " 'recent',\n",
       " 'memory',\n",
       " 'part',\n",
       " 'reason',\n",
       " 'film',\n",
       " 'work',\n",
       " 'well',\n",
       " 'clever',\n",
       " 'setup',\n",
       " 'various',\n",
       " 'gag',\n",
       " 'slapstick',\n",
       " 'often',\n",
       " 'regard',\n",
       " 'unsophisticated',\n",
       " 'even',\n",
       " 'crude',\n",
       " 'form',\n",
       " 'comedy',\n",
       " 'think',\n",
       " 'part',\n",
       " 'reason',\n",
       " 'often',\n",
       " 'seem',\n",
       " 'force',\n",
       " 'see',\n",
       " 'movie',\n",
       " 'character',\n",
       " 'start',\n",
       " 'run',\n",
       " 'something',\n",
       " 'crash',\n",
       " 'face',\n",
       " 'first',\n",
       " 'pole',\n",
       " 'many',\n",
       " 'time',\n",
       " 'start',\n",
       " 'wonder',\n",
       " 'pole',\n",
       " 'first',\n",
       " 'place',\n",
       " 'people',\n",
       " 'watch',\n",
       " 'go',\n",
       " 'le',\n",
       " 'vacances',\n",
       " 'de',\n",
       " 'hulot',\n",
       " 'gag',\n",
       " 'build',\n",
       " 'upon',\n",
       " 'often',\n",
       " 'start',\n",
       " 'relatively',\n",
       " 'low',\n",
       " 'key',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'example',\n",
       " 'hulot',\n",
       " 'painting',\n",
       " 'side',\n",
       " 'small',\n",
       " 'row',\n",
       " 'boat',\n",
       " 'beach',\n",
       " 'back',\n",
       " 'turn',\n",
       " 'paint',\n",
       " 'get',\n",
       " 'caught',\n",
       " 'oncoming',\n",
       " 'wave',\n",
       " 'wash',\n",
       " 'away',\n",
       " 'come',\n",
       " 'back',\n",
       " 'side',\n",
       " 'boat',\n",
       " 'cross',\n",
       " 'get',\n",
       " 'hulot',\n",
       " 'step',\n",
       " 'boat',\n",
       " 'unknowingly',\n",
       " 'crack',\n",
       " 'actually',\n",
       " 'take',\n",
       " 'boat',\n",
       " 'water',\n",
       " 'break',\n",
       " 'half',\n",
       " 'two',\n",
       " 'half',\n",
       " 'flip',\n",
       " 'trap',\n",
       " 'inside',\n",
       " 'bystander',\n",
       " 'mistake',\n",
       " 'shark',\n",
       " 'fin',\n",
       " 'panic',\n",
       " 'beach',\n",
       " 'ensues',\n",
       " 'tati',\n",
       " 'waste',\n",
       " 'single',\n",
       " 'opportunity',\n",
       " 'humor',\n",
       " 'scene',\n",
       " 'might',\n",
       " 'yield',\n",
       " 'one',\n",
       " 'joke',\n",
       " 'comedy',\n",
       " 'good',\n",
       " 'least',\n",
       " 'four',\n",
       " 'five',\n",
       " 'film',\n",
       " 'say',\n",
       " 'comedy',\n",
       " 'relies',\n",
       " 'frustrate',\n",
       " 'audience',\n",
       " 'expectation',\n",
       " 'le',\n",
       " 'vacances',\n",
       " 'de',\n",
       " 'hulot',\n",
       " 'succeed',\n",
       " 'brilliantly',\n",
       " 'area',\n",
       " 'well',\n",
       " 'tati',\n",
       " 'accomplishes',\n",
       " 'largely',\n",
       " 'sort',\n",
       " 'deadpan',\n",
       " 'understatement',\n",
       " 'hulot',\n",
       " 'go',\n",
       " 'separate',\n",
       " 'room',\n",
       " 'dinner',\n",
       " 'start',\n",
       " 'play',\n",
       " 'record',\n",
       " 'defeaningly',\n",
       " 'loud',\n",
       " 'volume',\n",
       " 'fight',\n",
       " 'shout',\n",
       " 'match',\n",
       " 'ensue',\n",
       " 'instead',\n",
       " 'waiter',\n",
       " 'calmly',\n",
       " 'walk',\n",
       " 'shuts',\n",
       " 'power',\n",
       " 'room',\n",
       " 'disconnect',\n",
       " 'record',\n",
       " 'player',\n",
       " 'leave',\n",
       " 'puzzle',\n",
       " 'hulot',\n",
       " 'sit',\n",
       " 'dark',\n",
       " 'tati',\n",
       " 'also',\n",
       " 'us',\n",
       " 'run',\n",
       " 'gag',\n",
       " 'effect',\n",
       " 'allow',\n",
       " 'keep',\n",
       " 'run',\n",
       " 'far',\n",
       " 'longer',\n",
       " 'comedy',\n",
       " 'director',\n",
       " 'would',\n",
       " 'often',\n",
       " 'see',\n",
       " 'come',\n",
       " 'think',\n",
       " 'oh',\n",
       " 'go',\n",
       " 'lo',\n",
       " 'behold',\n",
       " 'example',\n",
       " 'recur',\n",
       " 'joke',\n",
       " 'hulot',\n",
       " 'noisy',\n",
       " 'sputter',\n",
       " 'car',\n",
       " 'engine',\n",
       " 'wake',\n",
       " 'everyone',\n",
       " 'middle',\n",
       " 'night',\n",
       " 'exterior',\n",
       " 'shot',\n",
       " 'reveals',\n",
       " 'hotel',\n",
       " 'light',\n",
       " 'come',\n",
       " 'one',\n",
       " 'one',\n",
       " 'image',\n",
       " 'turn',\n",
       " 'finale',\n",
       " 'give',\n",
       " 'away',\n",
       " 'say',\n",
       " 'involves',\n",
       " 'lot',\n",
       " 'noise',\n",
       " 'middle',\n",
       " 'night',\n",
       " 'car',\n",
       " 'engine',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'produce',\n",
       " 'end',\n",
       " 'one',\n",
       " 'two',\n",
       " 'element',\n",
       " 'really',\n",
       " 'make',\n",
       " 'four',\n",
       " 'star',\n",
       " 'film',\n",
       " 'oppose',\n",
       " 'merely',\n",
       " 'average',\n",
       " 'clever',\n",
       " 'comedy',\n",
       " 'much',\n",
       " 'laugh',\n",
       " 'film',\n",
       " 'think',\n",
       " 'occasionally',\n",
       " 'tati',\n",
       " 'top',\n",
       " 'end',\n",
       " 'really',\n",
       " 'make',\n",
       " 'work',\n",
       " 'complete',\n",
       " 'view',\n",
       " 'experience',\n",
       " 'suffice',\n",
       " 'say',\n",
       " 'important',\n",
       " 'aspect',\n",
       " 'film',\n",
       " 'never',\n",
       " 'seem',\n",
       " 'disdainful',\n",
       " 'character',\n",
       " 'easily',\n",
       " 'could',\n",
       " 'turn',\n",
       " 'table',\n",
       " 'hulot',\n",
       " 'guest',\n",
       " 'exact',\n",
       " 'kind',\n",
       " 'revenge',\n",
       " 'alternatively',\n",
       " 'could',\n",
       " 'portrayed',\n",
       " 'others',\n",
       " 'humorless',\n",
       " 'curmudgeon',\n",
       " 'instead',\n",
       " 'tati',\n",
       " 'seem',\n",
       " 'regard',\n",
       " 'character',\n",
       " 'cheerful',\n",
       " 'amusement',\n",
       " 'anything',\n",
       " 'else',\n",
       " 'invite',\n",
       " 'audience',\n",
       " 'like',\n",
       " 'however',\n",
       " 'strange',\n",
       " 'irritate',\n",
       " 'might',\n",
       " 'seem',\n",
       " 'le',\n",
       " 'vacances',\n",
       " 'de',\n",
       " 'hulot',\n",
       " 'subtitle',\n",
       " 'dialogue',\n",
       " 'sparse',\n",
       " 'part',\n",
       " 'terribly',\n",
       " 'essential',\n",
       " 'flow',\n",
       " 'event',\n",
       " 'anyone',\n",
       " 'taste',\n",
       " 'kind',\n",
       " 'absurd',\n",
       " 'humor',\n",
       " 'ought',\n",
       " 'make',\n",
       " 'film',\n",
       " 'next',\n",
       " 'rental',\n",
       " 'video',\n",
       " 'store',\n",
       " 'note',\n",
       " 'le',\n",
       " 'vacances',\n",
       " 'de',\n",
       " 'hulot',\n",
       " 'rat',\n",
       " 'mpaa',\n",
       " 'would',\n",
       " 'receive',\n",
       " 'pg',\n",
       " 'rating']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_review(documents[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents  = [(clean_review(document),category) for document,category in documents ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_documents = documents[0:1500]\n",
    "testing_documents = documents[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for doc in training_documents:\n",
    "    all_words += doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(all_words)\n",
    "common = freq.most_common(3000)\n",
    "features = [i[0] for i in common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(words):\n",
    "    current_features = {}\n",
    "    words_set = set(words)\n",
    "    for w in features:\n",
    "        current_features[w] = w in words_set\n",
    "    return current_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = get_feature_dict(training_documents[0][0])\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [(get_feature_dict(doc), category) for doc, category in training_documents]\n",
    "testing_data = [(get_feature_dict(doc), category) for doc, category in training_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier = NaiveBayesClassifier.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classfier, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classfier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from nltk.classify.scikitlearn import SklearnClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "classifier_sklearn = SklearnClassifier(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sklearn.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier_sklearn, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "classifier_sklearn1 = SklearnClassifier(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sklearn1.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.classify.accuracy(classifier_sklearn1, testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
