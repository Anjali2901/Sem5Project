{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 35.37604456824513 %\n",
      "Negative tweets percentage: 18.662952646239553 %\n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "@realDonaldTrump Why don't you want to allow people to apply for asylum at the border? That IS the legal way to do… https://t.co/WOQiJSWzB5\n",
      "@Suresh05333402 @_May_I_Tweet_ @tweetsakshi @ncbn @narendramodi Haha cbn is 2 faced crook . He is just a congress boot licker now\n",
      "Lol you bitches don't even know how to be real friends... Just a bunch of messy, fake ass, 2 faced, scandalous, no loyalty having whores.\n",
      "GOING TO VEGAS ON DEC 28TH- JAN 2 LOCKED AND LOADED. YOUR INVITED FACED ASS. WHOEVER GOT THEY MONEY READY AND A WAY… https://t.co/9HQowZOLzX\n",
      "2 days after this day a mysterious fire broke out directly across from camp. There was a high possibility this fire… https://t.co/DN5UN23ZPh\n",
      "RT @Thompson_DavidW: Newest Release #MollMania \n",
      "Book 2-His Father's Blood\n",
      "The demon Laris has returned! The #Supernatural forces faced by J…\n",
      "NU quickly faced with fourth down and 2. Fitz takes a timeout with a big decision in front of him.\n",
      "Really glad im banned from groups at the moment\n",
      "Will save me so much hassle. Cos really want to start a fight with… https://t.co/R1sYlvSJWc\n",
      "@MCMComicCon @matthewmercer @Marisha_Ray Please book a bigger location the next time. Pritty please.🙏 And a thanks… https://t.co/UAqVseLsHj\n",
      "RT @ArfaSays_: MUKHTAR AHMED played 6 T20i for Pakistan in 2015. Scores in first three inns were 37, 83, 62 &amp; last three inns 2, 4, 4 - tha…\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "I Know A lot Of Weak , Miserable, Fake , Funny Acting , 2 Faced , Petty , &amp; Messy Bitches 👌🏾💯 That's Why I Just keep To My Lonely 👏🏾😘\n",
      "I did not realize how stupid the majority of the community is... Keep the online pimping alive.. 2 faced bitches al… https://t.co/abhncFdLDj\n",
      "When girls be talking about how they hate 2-faced people, but they as bad as the next bitch.🐸☕️\n",
      "I'm selective as fuck.... Bitches be 2 faced, fake, phony, and just plain ole trifling...I can't be bothered 😬 fuck a friend give me a check\n",
      "@suicide_boi Any design that can put you up a one way street the wrong way is dangerous. I was only there for secon… https://t.co/nC0PXXusck\n",
      "How I been seeing everybody lately..\n",
      "\n",
      "🤡            🎭          🐭    🐍         🤪\n",
      "👕             👕         👕    👕… https://t.co/tpKZjZkWmC\n",
      "RT @deba247: I faced the worst cab service by Uber, due to which I missed my flight and I had to spend Rs. 5.7k to book the next fIight. Pe…\n",
      "RT @allisonverhovec: 2 faced people are so annoying. be straight up or fuck off\n",
      "Centralia wins set one versus Spearville 25-14 to take a 1-0 lead in the Championship Match. That was a tough set f… https://t.co/XN5R12UwPY\n",
      "@DonaldJTrumpJr Why dont u 2 faced idiot trumps shut up with the hate u and daddy trump says to others is stupid pe… https://t.co/vSHuwgboNK\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "import csv\n",
    "\n",
    "class TwitterClient(object): \n",
    "\n",
    "    def __init__(self): \n",
    "        consumer_key = \"rXBTXz6yE6VjactwIFfQEHLwX\"\n",
    "        consumer_secret = \"3wluIGBoyitUyr8m0HRhiap6UhUFkGskWJ2DA0J7v4es9Dfhwo\"\n",
    "        access_token = \"1055057699078107137-ntZ1ReqvsUvpPDJpKjUaV5oc0m8zhb\"\n",
    "        access_token_secret = \"39Ew12bFgpyITIjo9GOhvD2R3mlpwvrbvAaCE5XmGQYm4\"\n",
    "\n",
    "\n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "\n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "\n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "\n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "\n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            file_name = open(\"test.txt\",\"r\") \n",
    "            train = \"train.csv\"\n",
    "            csvf = open(\"train.csv\",\"w\")\n",
    "            csvwriter = csv.writer(csvf)\n",
    "            row = [\"text\",\"sentiment\"]\n",
    "            csvwriter.writerow(row)\n",
    "            for line in file_name:\n",
    "                fetched_tweets = self.api.search(q = line, count = count) \n",
    "  \n",
    "                # parsing tweets one by one \n",
    "                for tweet in fetched_tweets: \n",
    "                    # empty dictionary to store required params of a tweet \n",
    "                    parsed_tweet = {} \n",
    "  \n",
    "                    # saving text of tweet \n",
    "                    parsed_tweet['text'] = tweet.text \n",
    "                    # saving sentiment of tweet \n",
    "                    parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "\n",
    "                    # appending parsed tweet to tweets list \n",
    "                    if tweet.retweet_count > 0: \n",
    "                        # if tweet has retweets, ensure that it is appended only once \n",
    "                        if parsed_tweet not in tweets: \n",
    "                            tweets.append(parsed_tweet) \n",
    "                            \n",
    "                    else: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                    #tweets is our list \n",
    "                    f=0\n",
    "                    val1 = \"\"\n",
    "                    val2 = \"\"\n",
    "                    for i in tweets:\n",
    "                        for key, value in i.items():\n",
    "                            if(f==0):\n",
    "                                val1=value\n",
    "                                f=1\n",
    "                            else :\n",
    "                                f=0\n",
    "                                val2=value\n",
    "                        row = [val1.encode(\"utf8\"),val2.encode(\"utf8\")]\n",
    "                        csvwriter.writerow(row)  \n",
    "            #csvf.close()\n",
    "            return tweets \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "\n",
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Donald Trump', count = 200) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    # percentage of neutral tweets \n",
    "    #print(\"Neutral tweets percentage: {} %\".format(100*len(tweets - ntweets - ptweets)/len(tweets))) \n",
    "\n",
    "    # printing first 5 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text']) \n",
    "\n",
    "    # printing first 5 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text']) \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'RT @Irshad5676: Shocks #Ajith fans faced from the day they announced this film... \\n1-#SiruthaiSiva director\\n2-#SathyaJyothi producer\\n3-#Vis\\xe2\\x80\\xa6'\n"
     ]
    }
   ],
   "source": [
    "f1 = \"res1.csv\"\n",
    "csvf = open(f1,\"w\")\n",
    "csvwriter = csv.writer(csvf)\n",
    "row = [\"text\",\"sentiment\"]\n",
    "csvwriter.writerow(row)\n",
    "a = [{'text': '@BSNL_WB @BSNLCorporate Faced poor network and several call drops in my area Vill&amp;PO- Ranihati, PS- Bagda,N24PGS, W… https://t.co/hPgYMtEsei', 'sentiment': 'negative'},{'text': 'RT @Irshad5676: Shocks #Ajith fans faced from the day they announced this film... \\n1-#SiruthaiSiva director\\n2-#SathyaJyothi producer\\n3-#Vis…', 'sentiment': 'neutral'}]\n",
    "\n",
    "#print(a)\n",
    "f=0\n",
    "val1 = \"\"\n",
    "val2 = \"\"\n",
    "for i in a:\n",
    "    for key, value in i.items():\n",
    "        if(f==0):\n",
    "            val1=value\n",
    "            f=1\n",
    "        else :\n",
    "            f=0\n",
    "            val2=value\n",
    "    row = [val1.encode(\"utf8\"),val2.encode(\"utf8\")]\n",
    "    csvwriter.writerow(row)\n",
    "print(val1.encode(\"utf8\"))  \n",
    "csvf.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'When girls be talking about how they hate 2-...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'When girls be talking about how they hate 2-...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b\"I'm selective as fuck.... Bitches be 2 faced...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'When girls be talking about how they hate 2-...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b\"I'm selective as fuck.... Bitches be 2 faced...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b\"@realDonaldTrump Why don't you want to allow...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b'When girls be talking about how they hate 2-...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b\"I'm selective as fuck.... Bitches be 2 faced...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b\"@realDonaldTrump Why don't you want to allow...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b'@Suresh05333402 @_May_I_Tweet_ @tweetsakshi ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'When girls be talking about how they hate 2-...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b\"I'm selective as fuck.... Bitches be 2 faced...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b\"@realDonaldTrump Why don't you want to allow...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'@Suresh05333402 @_May_I_Tweet_ @tweetsakshi ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b\"Lol you bitches don't even know how to be re...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b\"I Know A lot Of Weak , Miserable, Fake , Fun...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b'I did not realize how stupid the majority of...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120236</th>\n",
       "      <td>b'RT @ricsl1600: Like every man of sense and g...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120237</th>\n",
       "      <td>b'Like every man of sense and good feeling, I ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120238</th>\n",
       "      <td>b'RT @DoyleAbominator: Repost from doylewolfga...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120239</th>\n",
       "      <td>b'Repost from @doylewolfgangvonfrankenstein us...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120240</th>\n",
       "      <td>b'Repost from doylewolfgangvonfrankenstein usi...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120241</th>\n",
       "      <td>b'Repost from doylewolfgangvonfrankenstein usi...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120242</th>\n",
       "      <td>b'\\xe7\\xa7\\x81\\xe3\\x80\\x81\\xe5\\xad\\xa6\\xe5\\x8b...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120243</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120244</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120245</th>\n",
       "      <td>b'@TheLondonDebate @KeloidKrown @JohnCarson64 ...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120246</th>\n",
       "      <td>b'\\xe2\\x80\\x9cI have been in a serious battle ...</td>\n",
       "      <td>b'negative'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120247</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120248</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120249</th>\n",
       "      <td>b'Our #village can have no peace until Cora th...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120250</th>\n",
       "      <td>b'@DestiGrace1 @craigunger @GOP detest, abhor,...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120251</th>\n",
       "      <td>b\"abominate /\\xc9\\x99b\\xc9\\x91'm\\xc9\\x99n\\xc3\\...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120252</th>\n",
       "      <td>b'an immensity considers a wench: abominate, a...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120253</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120254</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120255</th>\n",
       "      <td>b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120256</th>\n",
       "      <td>b'RT @jahhh_nct_: Don\\xe2\\x80\\x99t abominate a...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120257</th>\n",
       "      <td>b'a supplication is a terrine: abominate, yet ...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120258</th>\n",
       "      <td>b'According to Soundex, abound sounds like app...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120259</th>\n",
       "      <td>b'RT @ricsl1600: Like every man of sense and g...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120260</th>\n",
       "      <td>b'Like every man of sense and good feeling, I ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120261</th>\n",
       "      <td>b'@AmritAgrawal16 @samjawed65 @free_thinker @t...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120262</th>\n",
       "      <td>b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120263</th>\n",
       "      <td>b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...</td>\n",
       "      <td>b'positive'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120264</th>\n",
       "      <td>b\"Denominator, go Decatur, go Decatur\\nIt's th...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120265</th>\n",
       "      <td>b'RT @englishisamust: Hesitate \\xe0\\xb8\\xa5\\xe...</td>\n",
       "      <td>b'neutral'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text    sentiment\n",
       "0       b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "1       b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "2       b'I did not realize how stupid the majority of...  b'negative'\n",
       "3       b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "4       b'I did not realize how stupid the majority of...  b'negative'\n",
       "5       b'When girls be talking about how they hate 2-...  b'negative'\n",
       "6       b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "7       b'I did not realize how stupid the majority of...  b'negative'\n",
       "8       b'When girls be talking about how they hate 2-...  b'negative'\n",
       "9       b\"I'm selective as fuck.... Bitches be 2 faced...  b'negative'\n",
       "10      b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "11      b'I did not realize how stupid the majority of...  b'negative'\n",
       "12      b'When girls be talking about how they hate 2-...  b'negative'\n",
       "13      b\"I'm selective as fuck.... Bitches be 2 faced...  b'negative'\n",
       "14      b\"@realDonaldTrump Why don't you want to allow...  b'positive'\n",
       "15      b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "16      b'I did not realize how stupid the majority of...  b'negative'\n",
       "17      b'When girls be talking about how they hate 2-...  b'negative'\n",
       "18      b\"I'm selective as fuck.... Bitches be 2 faced...  b'negative'\n",
       "19      b\"@realDonaldTrump Why don't you want to allow...  b'positive'\n",
       "20      b'@Suresh05333402 @_May_I_Tweet_ @tweetsakshi ...  b'positive'\n",
       "21      b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "22      b'I did not realize how stupid the majority of...  b'negative'\n",
       "23      b'When girls be talking about how they hate 2-...  b'negative'\n",
       "24      b\"I'm selective as fuck.... Bitches be 2 faced...  b'negative'\n",
       "25      b\"@realDonaldTrump Why don't you want to allow...  b'positive'\n",
       "26      b'@Suresh05333402 @_May_I_Tweet_ @tweetsakshi ...  b'positive'\n",
       "27      b\"Lol you bitches don't even know how to be re...  b'positive'\n",
       "28      b\"I Know A lot Of Weak , Miserable, Fake , Fun...  b'negative'\n",
       "29      b'I did not realize how stupid the majority of...  b'negative'\n",
       "...                                                   ...          ...\n",
       "120236  b'RT @ricsl1600: Like every man of sense and g...  b'positive'\n",
       "120237  b'Like every man of sense and good feeling, I ...  b'positive'\n",
       "120238  b'RT @DoyleAbominator: Repost from doylewolfga...   b'neutral'\n",
       "120239  b'Repost from @doylewolfgangvonfrankenstein us...   b'neutral'\n",
       "120240  b'Repost from doylewolfgangvonfrankenstein usi...   b'neutral'\n",
       "120241  b'Repost from doylewolfgangvonfrankenstein usi...   b'neutral'\n",
       "120242  b'\\xe7\\xa7\\x81\\xe3\\x80\\x81\\xe5\\xad\\xa6\\xe5\\x8b...   b'neutral'\n",
       "120243  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...   b'neutral'\n",
       "120244  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...  b'positive'\n",
       "120245  b'@TheLondonDebate @KeloidKrown @JohnCarson64 ...  b'negative'\n",
       "120246  b'\\xe2\\x80\\x9cI have been in a serious battle ...  b'negative'\n",
       "120247  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...   b'neutral'\n",
       "120248  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...  b'positive'\n",
       "120249  b'Our #village can have no peace until Cora th...   b'neutral'\n",
       "120250  b'@DestiGrace1 @craigunger @GOP detest, abhor,...   b'neutral'\n",
       "120251  b\"abominate /\\xc9\\x99b\\xc9\\x91'm\\xc9\\x99n\\xc3\\...   b'neutral'\n",
       "120252  b'an immensity considers a wench: abominate, a...   b'neutral'\n",
       "120253  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...   b'neutral'\n",
       "120254  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...  b'positive'\n",
       "120255  b'abominate -- \\xed\\x98\\x90\\xec\\x98\\xa4\\xed\\x9...   b'neutral'\n",
       "120256  b'RT @jahhh_nct_: Don\\xe2\\x80\\x99t abominate a...   b'neutral'\n",
       "120257  b'a supplication is a terrine: abominate, yet ...   b'neutral'\n",
       "120258  b'According to Soundex, abound sounds like app...   b'neutral'\n",
       "120259  b'RT @ricsl1600: Like every man of sense and g...  b'positive'\n",
       "120260  b'Like every man of sense and good feeling, I ...  b'positive'\n",
       "120261  b'@AmritAgrawal16 @samjawed65 @free_thinker @t...   b'neutral'\n",
       "120262  b'Rev. Dr. Moszell MORITZ JAY BLACKMONAHAN WIL...   b'neutral'\n",
       "120263  b'Rev Dr Moszell MORITZ JAY BLACKMONAHAN WILL ...  b'positive'\n",
       "120264  b\"Denominator, go Decatur, go Decatur\\nIt's th...   b'neutral'\n",
       "120265  b'RT @englishisamust: Hesitate \\xe0\\xb8\\xa5\\xe...   b'neutral'\n",
       "\n",
       "[120266 rows x 2 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"train.csv\");\n",
    "df1 = df\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "y = df['sentiment']\n",
    "x = df['text']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'],df['sentiment'] , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROCESSED_FILE = 'train-processed.csv'\n",
    "TEST_PROCESSED_FILE = 'test-processed.csv'\n",
    "X_test.to_csv(TEST_PROCESSED_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = pd.concat([X_train, y_train,], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train.to_csv(TRAIN_PROCESSED_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-d5d09f6873b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m  \u001b[0mwrite_status\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'write_status'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import utils\n",
    "from utils import  write_status\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def preprocess_word(word):\n",
    "    # Remove punctuation\n",
    "    word = word.strip('\\'\"?!,.():;')\n",
    "    # Convert more than 2 letter repetitions to 2 letter\n",
    "    # funnnnny --> funny\n",
    "    word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "    # Remove - & '\n",
    "    word = re.sub(r'(-|\\')', '', word)\n",
    "    return word\n",
    "\n",
    "def is_valid_word(word):\n",
    "    # Check if word begins with an alphabet\n",
    "    return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "def handle_emojis(tweet):\n",
    "    # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "    tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "    # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "    tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "    # Love -- <3, :*\n",
    "    tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "    # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "    tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "    # Sad -- :-(, : (, :(, ):, )-:\n",
    "    tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "    # Cry -- :,(, :'(, :\"(\n",
    "    tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "    return tweet\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    processed_tweet = []\n",
    "    # Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    # Replaces URLs with the word URL\n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "    # Replace @handle with the word USER_MENTION\n",
    "    tweet = re.sub(r'@[\\S]+', 'USER_MENTION', tweet)\n",
    "    # Replaces #hashtag with hashtag\n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    # Remove RT (retweet)\n",
    "    tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "    # Replace 2+ dots with space\n",
    "    tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "    # Strip space, \" and ' from tweet\n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    # Replace emojis with either EMO_POS or EMO_NEG\n",
    "    tweet = handle_emojis(tweet)\n",
    "    # Replace multiple spaces with a single space\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    words = tweet.split()\n",
    "\n",
    "    for word in words:\n",
    "        word = preprocess_word(word)\n",
    "        if is_valid_word(word):\n",
    "            if use_stemmer:\n",
    "                word = str(porter_stemmer.stem(word))\n",
    "            processed_tweet.append(word)\n",
    "\n",
    "    return ' '.join(processed_tweet)\n",
    "\n",
    "def preprocess_csv(csv_file_name, processed_file_name, test_file=False):\n",
    "    save_to_file = open(processed_file_name, 'w')\n",
    "\n",
    "    with open(csv_file_name, 'r') as csv:\n",
    "        lines = csv.readlines()\n",
    "        total = len(lines)\n",
    "        for i, line in enumerate(lines):\n",
    "            tweet_id = line[:line.find(',')]\n",
    "            if not test_file:\n",
    "                line = line[1 + line.find(','):]\n",
    "                positive = int(line[:line.find(',')])\n",
    "            line = line[1 + line.find(','):]\n",
    "            tweet = line\n",
    "            processed_tweet = preprocess_tweet(tweet)\n",
    "            if not test_file:\n",
    "                save_to_file.write('%s,%d,%s\\n' %\n",
    "                                   (tweet_id, positive, processed_tweet))\n",
    "            else:\n",
    "                save_to_file.write('%s,%s\\n' %\n",
    "                                   (tweet_id, processed_tweet))\n",
    "            write_status(i + 1, total)\n",
    "    save_to_file.close()\n",
    "    print('\\nSaved processed tweets to: %s' % processed_file_name)\n",
    "    return processed_file_name\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 2:\n",
    "        print('Usage: python preprocess.py <raw-CSV>')\n",
    "        exit()\n",
    "    use_stemmer = False\n",
    "    csv_file_name = sys.argv[1]\n",
    "    processed_file_name = sys.argv[1][:-4] + '-processed.csv'\n",
    "    if use_stemmer:\n",
    "        porter_stemmer = PorterStemmer()\n",
    "        processed_file_name = sys.argv[1][:-4] + '-processed-stemmed.csv'\n",
    "    preprocess_csv(csv_file_name, processed_file_name, test_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'utils' has no attribute 'file_to_wordset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-631fdc178102>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_PROCESSED_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPOSITIVE_WORDS_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNEGATIVE_WORDS_FILE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Correct = %.2f%%'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-128-631fdc178102>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(processed_csv, test_file, **params)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_csv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mpositive_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_to_wordset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'positive_words'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mnegative_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_to_wordset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'negative_words'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'utils' has no attribute 'file_to_wordset'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Classifies a tweet based on the number of positive and negative words in it\n",
    "POSITIVE_WORDS_FILE = 'positive-words.txt'\n",
    "NEGATIVE_WORDS_FILE = 'negative-words.txt'\n",
    "TRAIN = True\n",
    "\n",
    "\n",
    "def classify(processed_csv, test_file=True, **params):\n",
    "    positive_words = utils.file_to_wordset(params.pop('positive_words'))\n",
    "    negative_words = utils.file_to_wordset(params.pop('negative_words'))\n",
    "    predictions = []\n",
    "    with open(processed_csv, 'r') as csv:\n",
    "        for line in csv:\n",
    "            if test_file:\n",
    "                tweet_id, tweet = line.strip().split(',')\n",
    "            else:\n",
    "                tweet_id, label, tweet = line.strip().split(',')\n",
    "            pos_count, neg_count = 0, 0\n",
    "            for word in tweet.split():\n",
    "                if word in positive_words:\n",
    "                    pos_count += 1\n",
    "                elif word in negative_words:\n",
    "                    neg_count += 1\n",
    "            # print pos_count, neg_count\n",
    "            prediction = 1 if pos_count >= neg_count else 0\n",
    "            if test_file:\n",
    "                predictions.append((tweet_id, prediction))\n",
    "            else:\n",
    "                predictions.append((tweet_id, int(label), prediction))\n",
    "    return predictions\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if TRAIN:\n",
    "        predictions = classify(TRAIN_PROCESSED_FILE, test_file=(not TRAIN), positive_words=POSITIVE_WORDS_FILE, negative_words=NEGATIVE_WORDS_FILE)\n",
    "        correct = sum([1 for p in predictions if p[1] == p[2]]) * 100.0 / len(predictions)\n",
    "        print('Correct = %.2f%%' % correct)\n",
    "    else:\n",
    "        predictions = classify(TEST_PROCESSED_FILE, test_file=(not TRAIN), positive_words=POSITIVE_WORDS_FILE, negative_words=NEGATIVE_WORDS_FILE)\n",
    "        utils.save_results_to_csv(predictions, 'baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
